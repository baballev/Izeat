= PAN3 RAPPORT

== AVANCEMENT DES MODULES

=== Intégration

L'intégration de notre application se sépare en trois parties :

* Intégrer la partie client : la reconnaissance d'image à l'application android
* Intégrer la partie serveur : faire fonctionner la base de donnée avec le web service et le moteur de recommendation
* Intégrer la partie serveur au client

L'intégration des modules propres aux clients (la reconnaissance d'image) a été entièrement faite, y compris la 
correspondance avec la charte graphique : 

On est donc capable depuis l'application
de cliquer sur le bouton + qui nous donne la possibilité d'accéder au bouton photo 
qui lance alors une activité qui intègre le modèle entrainé par Vincent et Léa.
On peut alors faire tout ce qui a trait au modèle de reconnaissance d'image. Le 
retour à l'application avec ajout n'est pas encore géré car cela relève de
l'intégration client -> serveur qui est en cours.

L'intégration des modules propres au serveur n'a pas encore pu être faite:

Johnathan était responsable de l'intégration de ce module, or au moment du pan3
il était occupé principalement à faire avancer le module IA/recommendation qui 
rencontrait des problèmes. La base de donnée a néanmoins fourni toute les méthodes
nécessaires à son utilisation et on a pu résoudre le problème de l'intégration
de celle ci dans le serveur. Ce jeu de méthodes simplifiera grandement l'intégration
avec les autres modules.

Comme cela a été dit plus haut, l'intégration client -> server est aussi en cours.
Le module android travaille avec celui du web service pour permettre la communication
de l'application avec le serveur.

Même si ils ne sont pas répertoriés exactement, de nombreux test ont été fait pour
l'intégration de la reconnaissance d'image. Ils ont été fait aux différents stades
de l'intégration, sur différents émulateurs comme sur un vrai téléphone android. 

=== Android

Concernant le module android, nous avons implémenter tous les différents onglets qui composent l'application:

* onglet recettes
* onglet produits 
* onglet frigo
* onglet profil 

Les onglets recettes, produits et frigo se ressemblent beaucoup pour le moment puisqu'ils sont composés de recycler view qui afficheront respectivement
les recettes suggérées par l'IA, les produits recommandés et les produits ajoutés dans le frigo virtuel. De plus, les activités permettant de détailler 
les produits et les recettes lorsque l'on clique dessus sont crées mais pas encore liées aux éléments des recycler view. 

L'onglet profil a été créé mais pas encore complètement implémenté. 

Par ailleurs, nous avons crée un bouton add qui est présent sur chaque activité et qui permet à l'utilisateur d'ajouter rapidement un 
produit à son frigo virtuel. Lorsqu'il clique dessus, il se décompose en deux boutons: un bouton search qui affichera une barre de recherche pour trouver un 
produit dans une base de données, et un bouton "photo" qui permet d'ajouter un produit par reconnaissance d'image.

Lorsque l'utilisateur ouvre l'application, c'est l'activité de connexion qui s'affiche en premier: elle demande à l'utilisateur de rentrer son adresse mail 
mot de passe. Il peut ensuite accéder au contenu de l'application grâce à un bouton suivant qui permet d'arriver directement sur les recommendations de 
recettes, le coeur l'application. Si l'utilisateur n'est toujours pas connecté, il peut s'inscrire: il tombe alors sur une nouvelle activité
qui lui demande de rentrer un identifiant, adresse mail, mot de passe et des données sur lui, indispensables pour le bon fonctionnement de l'application, 
comme son poids, son age, son régime alimentaire ...

Pour finir, avec l'aide du module SES, nous avons essayé de travailler sur le design de l'application. Les activités sont épurées, pas trop chargées pour
ne pas perdre l'attention de l'utilisateur dans des détails inutiles. De plus, nous avons choisi une gamme de couleurs sobre et apaisante (marrons/beige) 
pour ne pas "agresser" l'utilisateur par des couleurs qui pourraient être trop vives. 

=== Reconnaissance d'image

Le modèle pour la reconnaissance d'image a été entrainé sur un dataset fait à a main de 10 catégories d'aliments. Les images ont été récoltées à partir d'ImageNet et de photos sur 
Instagram triées manuellement. Il y a environ 12 000 images de résolutions variées toutes ramenées à du 300x300x3. Le modèle a été intégré dans l'application android en optimisant la taille des poids enregistrés dans le modèle. On a observé que 
le modèle mais un peu de temps (environ 5 secondes) à faire une prédiction en condition réelles sur un portable andorid.
Nous essayerons donc d'exporter le modèle en optimisant la rapidité de la prédiction et aussi en essayant de diminuer le nombre de couches pour le rendre plus léger, quitte
à perdre en précision.

Un prototype fonctionnel de la reconnaissance d'image est implémenté dans l'application android, permettant de prendre une photo d'un aliment à partir de l'appareil
photo du téléphone, de la stocker temporairement sur le disque dur du téléphone, de charger la photo en mémoire et d'obtenir la prédiction avec un pourcentage qui indique
la probabilité des différentes classes d'aliments en accord avec le modèle.

Nous sommes actuellement contraint par le confinement puisque l'ordinateur possédant la puissance de calcul nécessaire (le GPU) et les datasets (de plusieurs centaines de Go) est à Palaiseau
et on ne peut pas y accéder. Néanmoins, on a un modèle fonctionnel sur git.

=== Service Web
Concernant le module web service, la partie d’interrogation d’OpenFoodFacts fonctionne que ce soit à partir de termes de recherche ou de code à barres.

La connexion Netbeans/Mysql est bien établie; on peut interroger la base de donnée izeat pour:
    * Ajouter un utilisateur.
    * Modifier le status de l’utilisateur à travers les différentes requetes SQL.
    * Récupérer les données d’un utilisateur ou d’une recette.
    * Mettre à jour la table fridge.
    * Ajouter une consommation à la table consumption.
    * Connecter l’utilisateur à son compte.
    
La sécurité des mots de passe est assurée par un hachage MD5: ainsi le mot de passe haché est stocké dans la table des utilisateurs "appUser" puis pour confirmer la connexion il suffit de comparer les mots de passe hachés.

Le client android parvient à interroger le web service comme il faut et à en récupérer les informations pertinentes.

=== Base de donnée
La base de donnée izeat comporte 5 tables: appUser, fridge, consumption, foodTypes et recipes.
La connexion Netbeans/Mysql est bien établie; on peut interroger la base de donnée izeat via les différentes requetes SQL.
On a préparé un fichier csv pour les recettes que l'application va recommander. 
Ce fichier est en cours de développement parce qu'on doit assurer que chaque recette ajoutée soit accompagnée de ses valeurs nutritionnelles.



== OBJECTIFS PAN4

=== Intégration

L'intégration va continuer évidemment et a pour objectif de terminer les 3 parties
citées. L'absence de Johnathan (qui était un des responsable du module) va bien évidemment 
compliquer la tâche. De plus la distance entre tous les membres du groupe à cause du contexte actuel
est le deuxième facteur critique concernant l'intégration du projet. 
La responsabilité de l'intégration du serveur, tout en restant
supervisée par le deuxième reponsable test et intégration (Pierre), va s'appuyer plus fortement
sur les responsables de chaque module qui devront (comme ils le faisaient déjà en partie),
s'attacher à fournir un jeu de méthodes facilement utilisables pour les autres modules.
Le fait qu'Alaeddine, David et Vincent soient tous les trois uniquement sur des 
modules dédiés au serveur va, on l'espère, faciliter cette tâche.

Nous allons, dans cette optique, revoir les exigences de chaque module à la baisse.
Nous préférons avoir un projet plus simple mais qui a une chance de fonctionner
qu'un projet aux grandes ambitions qui n'aboutiront pas. Ainsi, la priorité est
d'arriver à faire communiquer le client et le serveur, même si les tâches
grâce à cette communication sont limitées.

=== Android

Pour le pan4, les objectifs du module android sont les suivants: 

* Terminer l'onglet profil pour qu'il puisse afficher le détail des informations
rentrées par l'utilisateur lors de l'inscription et le suivi nutritif personnalisé. 
* créer la barre de recherche (deuxième mode d'ajout des éléments au frigo) 
* Permettre à l'utilisateur de visualiser les details des recettes et produits recommendés grâce à des activités déjà créées mais pas encore liées 
aux éléments des recycler view. 
* Travailler en collaboration avec le module webservice pour la communication avec le serveur : on doit pouvoir récupérer une liste de porduits ou une liste de recette mais aussi envoyer et récupérer le contenu du frigo virtuel. 

=== Reconnaissance d'image

Si nous pouvons à nouveau nous déplacer d'ici le PAN4, nous utiliserons les tickets de caisses franprix que nous avons 
accumulés au cours de l'année pour constituer un dataset qui va permettre d'ajouter une classe dans le modèle que l'on a entrainé.
On aura donc 11 classes dans le modèles: 10 aliments divers et 1 classe pour le ticket de caisse.
Si l'intégration se passe comme il faut, nous allons essayer d'implémenter un RNN déjà existant pour lire le texte sur le ticket de caisse lorsque celui ci est reconnu
sur l'image prise par l'appareil photo du téléphone.

Actuellement, on ne peut pas effectuer d'entrainement de notre modèle jusqu'à la fin du confinement pour les raisons evoquées ci-dessus dans la catégorie correspondante.

Diverses optimisations sont planifiées pour le PAN4 si nous en avons l'opportunité: 
* Réduire la profondeur du réseau de neurones utilisé pour le rendre moins volumineux une fois exporté dans l'application android.
* Débloquer quelques couches de convolutions du réseau pré-entrainé utilisé afin d'avoir de meilleurs résultats en terme de précision
* Optimiser l'exportation du modèle en terme de rapidité de la prédiction et non en volume de données afin de gagner en rapidité de l'expérience utilisateur.
